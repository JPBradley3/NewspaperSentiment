\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{verbatim}

\title{Seattle News Sentiment Analysis \\ Automated Scraping and Political Candidate Analysis}
\author{Data Science Project}
\date{\today}

\begin{document}

\maketitle

\section{Overview}

This project performs automated sentiment analysis on Seattle news articles, focusing on political candidates and municipal issues. The system scrapes articles from multiple news sources, analyzes sentiment using natural language processing, and generates visualizations showing sentiment patterns across sources, candidates, and themes.

\section{Project Structure}

\subsection{Core Components}

\begin{itemize}
    \item \texttt{newspaper\_sentiment\_scraper.py} - Python web scraper for collecting news articles
    \item \texttt{sentiment\_analysis.r} - R script for sentiment analysis and visualization
    \item \texttt{sentiment\_analysis\_clean.r} - Simplified version with enhanced error handling
\end{itemize}

\subsection{Data Sources}

The scraper targets the following Seattle news outlets:
\begin{itemize}
    \item Seattle Times
    \item KING 5 News
    \item KIRO 7 News
    \item KOMO News
    \item KUOW Public Radio
    \item The Stranger
    \item Capitol Hill Seattle
\end{itemize}

\section{Installation and Setup}

\subsection{Python Dependencies}

\begin{verbatim}
pip install requests beautifulsoup4 feedparser pandas
pip install urllib3 dataclasses logging functools
\end{verbatim}

\subsection{R Dependencies}

\begin{verbatim}
install.packages(c("tidyverse", "tidytext", "textdata", 
                   "ggplot2", "scales"))
\end{verbatim}

\section{Usage}

\subsection{Data Collection}

Run the Python scraper to collect articles:

\begin{verbatim}
python newspaper_sentiment_scraper.py
\end{verbatim}

This generates timestamped CSV files: \texttt{seattle\_news\_YYYYMMDD\_HHMMSS.csv}

\subsection{Sentiment Analysis}

Execute the R analysis script:

\begin{verbatim}
source("sentiment_analysis_clean.r")
\end{verbatim}

\section{Methodology}

\subsection{Web Scraping}

The scraper employs multiple strategies:
\begin{itemize}
    \item RSS feed parsing for structured data
    \item Direct web scraping with CSS selectors
    \item Wayback Machine fallback for unavailable content
    \item Weighted keyword relevance scoring
\end{itemize}

\subsection{Keyword Detection}

Articles are filtered using weighted keyword categories:

\textbf{High Priority (Weight = 3):}
\begin{itemize}
    \item 2025 mayoral candidates: Harrell, Wilson, Armstrong, Bliss, Mallahan, Molloy, Whelan, Willoughby, Savage
    \item Political terms: mayor, election, candidate, city council
\end{itemize}

\textbf{Medium Priority (Weight = 2):}
\begin{itemize}
    \item Urban issues: housing, homeless, transportation, budget
    \item Labor topics: union, organizing, workers
\end{itemize}

\textbf{Low Priority (Weight = 1):}
\begin{itemize}
    \item Policy terms: ordinance, legislation, referendum
\end{itemize}

\subsection{Sentiment Analysis}

The analysis uses the AFINN lexicon with the following process:

\begin{enumerate}
    \item Text preprocessing and tokenization
    \item Stop word removal
    \item Sentiment scoring: $S_{article} = \frac{\sum_{i=1}^{n} w_i}{n}$
    
    where $w_i$ is the AFINN score for word $i$ and $n$ is the word count
    \item Aggregation by source, candidate, and theme
\end{enumerate}

\section{Output Files}

\subsection{Data Files}

\begin{itemize}
    \item \texttt{article\_sentiments.csv} - Individual article sentiment scores
    \item \texttt{sentiment\_by\_source.csv} - Aggregated sentiment by news source
    \item \texttt{candidate\_sentiment\_by\_source.csv} - Candidate sentiment by source
    \item \texttt{sentiment\_by\_theme\_and\_source.csv} - Thematic sentiment analysis
    \item \texttt{candidate\_timeline\_data.csv} - Timeline data for candidates
\end{itemize}

\subsection{Visualizations}

\begin{itemize}
    \item \texttt{source\_sentiment\_plot.png} - Bar chart of sentiment by news source
    \item \texttt{candidate\_sentiment\_heatmap.png} - Heatmap of candidate sentiment across sources
    \item \texttt{candidate\_sentiment\_timeline.png} - Timeline of candidate sentiment over article sequence
    \item \texttt{thematic\_sentiment\_plot.png} - Faceted plot of sentiment by theme and source
\end{itemize}

\section{Key Features}

\subsection{Robust Data Collection}

\begin{itemize}
    \item Multiple fallback mechanisms for failed requests
    \item Rate limiting and respectful scraping practices
    \item Duplicate detection and removal
    \item Date format normalization
\end{itemize}

\subsection{Comprehensive Analysis}

\begin{itemize}
    \item Source-level sentiment comparison
    \item Candidate-specific sentiment tracking
    \item Thematic categorization (Politics, Urban Issues, Public Safety)
    \item Timeline analysis using article sequence
\end{itemize}

\subsection{Error Handling}

\begin{itemize}
    \item Graceful handling of network failures
    \item Alternative PNG saving when ggsave() fails
    \item Comprehensive logging and debugging output
\end{itemize}

\section{Configuration}

The scraper supports configuration via \texttt{scraping\_config.json}:

\begin{verbatim}
{
    "max_articles_per_source": 10,
    "request_timeout": 10,
    "delay_between_requests": 1.0,
    "min_content_length": 100,
    "use_wayback_fallback": true
}
\end{verbatim}

\section{Limitations and Considerations}

\begin{itemize}
    \item Limited to English-language sentiment analysis
    \item AFINN lexicon may not capture political context nuances
    \item Web scraping subject to site structure changes
    \item Timeline analysis uses article sequence rather than publication dates due to inconsistent date formats
\end{itemize}

\section{Future Enhancements}

\begin{itemize}
    \item Integration of transformer-based sentiment models
    \item Real-time monitoring and alerts
    \item Expanded keyword detection using NER
    \item Interactive dashboard development
    \item Cross-validation with human-annotated sentiment
\end{itemize}

\section{Technical Notes}

\subsection{Date Handling}

The system handles multiple date formats:
\begin{itemize}
    \item ISO 8601: \texttt{2025-01-30T14:30:00}
    \item RFC 2822: \texttt{Wed, 30 Jan 2025 14:30:00 +0000}
    \item US format: \texttt{January 30, 2025 at 2:30 pm PDT}
\end{itemize}

\subsection{Visualization Details}

All plots use consistent color schemes:
\begin{itemize}
    \item Positive sentiment: Blue
    \item Negative sentiment: Red
    \item Neutral reference: Dashed line at y=0
\end{itemize}

\section{Contact and Support}

For questions or issues, refer to the project documentation or examine the comprehensive logging output generated during execution.

\end{document}